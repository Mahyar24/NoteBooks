{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f603a175-52d1-4eff-b4ed-a4e606405a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ebf1b02-b5fb-4d88-9d7d-4e4f09b77413",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d543d423-d1d4-414d-b145-2fc8a4ba5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_network(\n",
    "    input_size=20,\n",
    "    num_hidden_layers=1,\n",
    "    num_hidden_units=100,\n",
    "    num_output_units=784,  # 28 * 28\n",
    "):\n",
    "\n",
    "    model = nn.Sequential()\n",
    "\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add_module(f\"g_fc_{i}\", nn.Linear(input_size, num_hidden_units))\n",
    "        model.add_module(f\"g_relu_{i}\", nn.LeakyReLU())\n",
    "\n",
    "    model.add_module(\n",
    "        f\"g_fc_{num_hidden_layers}\", nn.Linear(num_hidden_units, num_output_units)\n",
    "    )\n",
    "    model.add_module(\"g_tanh\", nn.Tanh())\n",
    "    return model\n",
    "\n",
    "\n",
    "def make_discriminator_network(\n",
    "    input_size=784,  # 28 * 28\n",
    "    num_hidden_layers=1,\n",
    "    num_hidden_units=100,\n",
    "    num_output_units=1,\n",
    "):\n",
    "\n",
    "    model = nn.Sequential()\n",
    "\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add_module(f\"d_fc_{i}\", nn.Linear(input_size, num_hidden_units))\n",
    "        model.add_module(f\"d_relu_{i}\", nn.LeakyReLU())\n",
    "        model.add_module(\"d_dropout\", nn.Dropout(p=0.5))\n",
    "        input_size = num_hidden_units\n",
    "\n",
    "    model.add_module(\n",
    "        f\"d_fc_{num_hidden_layers}\", nn.Linear(num_hidden_units, num_output_units)\n",
    "    )\n",
    "    model.add_module(\"d_sigmoid\", nn.Sigmoid())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90dc785d-1f7b-432f-a8de-7694f72fbfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b66096-4e2e-44a9-978d-0493d9a4218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noise(batch_size, z_size=20, mode='normal'):  # z_size == gen_model.input_size\n",
    "    if mode == 'normal':\n",
    "        return torch.randn(batch_size, z_size)\n",
    "    return (torch.rand(batch_size, z_size) * 2) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7088e78d-255f-4da6-ab04-c7e813715822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_train(d_model, g_model, criterion, d_optimizer, x):\n",
    "    d_model.zero_grad()\n",
    "    # Train on REAL data\n",
    "    x = x.view(BATCH_SIZE, -1).to(device)  # Flattening and transfering data to GPU\n",
    "    d_labels_real = torch.ones(BATCH_SIZE, 1, device=device)\n",
    "    d_proba_real = d_model(x)\n",
    "    d_loss_real = criterion(d_proba_real, d_labels_real)\n",
    "    # Train on NOISE\n",
    "    noise = create_noise(BATCH_SIZE).to(device)\n",
    "    g_output = g_model(noise)\n",
    "    d_proba_fake = d_model(g_output)\n",
    "    d_labels_fake = torch.zeros(BATCH_SIZE, 1, device=device)\n",
    "    d_loss_fake = criterion(d_proba_fake, d_labels_fake)\n",
    "    # Backprop and optimize d_model only\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    return d_loss.data.item(), d_proba_real.detach(), d_proba_fake.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e36dbd3-d099-4692-aa3e-2c0fcd586fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train(g_model, d_model, criterion, g_optimizer):\n",
    "    g_model.zero_grad()\n",
    "    noise = create_noise(BATCH_SIZE).to(device)\n",
    "    g_output = g_model(noise)\n",
    "    d_proba_fake = d_model(g_output)\n",
    "    g_labels_real = torch.ones(BATCH_SIZE, 1, device=device)\n",
    "    g_loss = criterion(d_proba_fake, g_labels_real)\n",
    "    # Backprop and optimize g_model only\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1be929c-05a1-4afb-aefd-e00854e2cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, criterion, g_optimizer, d_optimizer, data_loader, epochs=1):\n",
    "    all_d_losses = []\n",
    "    all_g_losses = []\n",
    "    all_d_real = []\n",
    "    all_d_fake = []\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        d_losses, g_losses = [], []\n",
    "        d_vals_real, d_vals_fake = [], []\n",
    "        \n",
    "        for i, (x, _) in enumerate(data_loader):\n",
    "            # Train and record d_model\n",
    "            d_loss, d_proba_real, d_proba_fake = discriminator_train(d_model, g_model, criterion, d_optimizer, x)\n",
    "            d_losses.append(d_loss)\n",
    "            d_vals_real.append(d_proba_real.mean().cpu())\n",
    "            d_vals_fake.append(d_proba_fake.mean().cpu())\n",
    "            # Train and record g_model\n",
    "            g_loss = generator_train(g_model, d_model, criterion, g_optimizer)\n",
    "            g_losses.append(g_loss)\n",
    "            \n",
    "        # Record for every epoch\n",
    "        all_d_losses.append(torch.tensor(d_losses).mean())\n",
    "        all_g_losses.append(torch.tensor(g_losses).mean())\n",
    "        all_d_real.append(torch.tensor(d_vals_real).mean())\n",
    "        all_d_fake.append(torch.tensor(d_vals_fake).mean())\n",
    "    \n",
    "        print(f'Epoch {epoch:03d} | Avg Losses >>'\n",
    "              f' G/D {all_g_losses[-1]:.4f}/{all_d_losses[-1]:.4f}'\n",
    "              f' [D-Real: {all_d_real[-1]:.4f}'\n",
    "              f' D-Fake: {all_d_fake[-1]:.4f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c4143d-4852-4000-bd89-08ad767ef52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ceee7cd-bdf8-4e83-a524-3d7a42943e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST('./mnist/', train=True, download=False, transform=transformer)\n",
    "train_dl = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f3eb70-0388-4f15-b26a-7c817383455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = make_generator_network().to(device)\n",
    "disc_model = make_discriminator_network().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "g_optimizer = torch.optim.AdamW(gen_model.parameters())\n",
    "d_optimizer = torch.optim.AdamW(disc_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161a981-f7f3-4306-aa74-32c288278729",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time train(gen_model, disc_model, criterion, g_optimizer, d_optimizer, train_dl, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
